#!/usr/bin/env python3
"""Complete E2E test: Create a glittery pink bunny using LM Studio + Blender."""

import asyncio
import aiohttp
import json
from pathlib import Path
from datetime import datetime


async def create_glittery_bunny_e2e():
    """Complete workflow: Prompt -> LLM -> Blender -> Render -> Save."""
    lm_studio_url = "http://localhost:1234/v1"
    blender_url = "http://localhost:3001"
    
    # Create output directory with timestamp
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_dir = Path(f"renders/glittery_bunny_{timestamp}")
    output_dir.mkdir(parents=True, exist_ok=True)
    
    async with aiohttp.ClientSession() as session:
        print("ğŸ°âœ¨ LL3M E2E: Creating Glittery Pink Bunny")
        print("=" * 60)
        
        # Step 1: Get model information
        print(f"\nğŸ¤– Step 1: Connecting to LM Studio")
        async with session.get(f"{lm_studio_url}/models") as response:
            models = await response.json()
            model_name = models["data"][0]["id"]
            print(f"âœ… Using model: {model_name}")
        
        # Step 2: Generate Blender code with AI
        print(f"\nğŸ¨ Step 2: Generating Blender Code for Glittery Pink Bunny")
        
        prompt = "a glittery pink bunny"
        
        system_prompt = """You are an expert Blender Python programmer. Create complete, working Blender Python code that:

1. Clears the default scene completely (including default cube, light, camera)
2. Creates a detailed bunny shape using Blender operations
3. Applies a glittery pink material with proper nodes and textures
4. Sets up professional lighting (multiple lights for good illumination)
5. Positions a camera for the best view of the bunny
6. Includes print statements for progress tracking

Requirements:
- Use only bpy operations (no external imports)
- Make the bunny actually look like a bunny (ears, body, tail)
- Create a truly glittery pink material with nodes
- Use proper Blender material nodes for metallic/glossy effects
- Set up multiple lights for professional rendering
- Position camera to showcase the bunny beautifully
- Include helpful print statements

Generate clean, complete, executable Blender Python code."""

        llm_request = {
            "model": model_name,
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"Create Blender Python code for: {prompt}"}
            ],
            "temperature": 0.7,
            "max_tokens": 2000
        }
        
        async with session.post(f"{lm_studio_url}/chat/completions", json=llm_request) as response:
            result = await response.json()
            generated_code = result["choices"][0]["message"]["content"]
            
            # Clean up the code (remove markdown if present)
            if "```python" in generated_code:
                generated_code = generated_code.split("```python")[1].split("```")[0].strip()
            elif "```" in generated_code:
                generated_code = generated_code.split("```")[1].split("```")[0].strip()
            
            print("âœ… Generated Blender code for glittery pink bunny")
            print("ğŸ“„ Code preview (first 10 lines):")
            for i, line in enumerate(generated_code.split('\n')[:10], 1):
                print(f"   {i:2d}: {line}")
            print("   ... (truncated)")
        
        # Save generated code
        code_path = output_dir / "generated_bunny_code.py"
        with open(code_path, "w") as f:
            f.write(generated_code)
        print(f"ğŸ’¾ Saved generated code to: {code_path}")
        
        # Step 3: Execute code in Blender
        print(f"\nğŸ­ Step 3: Executing Code in Blender")
        async with session.post(f"{blender_url}/execute", json={"code": generated_code}) as response:
            execution_result = await response.json()
            
            if execution_result["success"]:
                print("âœ… Code executed successfully in Blender!")
                print("ğŸ“‹ Execution logs:")
                for log in execution_result.get("logs", []):
                    if "STDOUT:" in log:
                        stdout = log.replace("STDOUT: ", "").strip()
                        for line in stdout.split('\n'):
                            if line.strip():
                                print(f"   ğŸ“ {line}")
            else:
                print(f"âŒ Code execution failed: {execution_result.get('error')}")
                return False
        
        # Step 4: Get scene information
        print(f"\nğŸ” Step 4: Verifying Scene Creation")
        async with session.get(f"{blender_url}/scene/info") as response:
            scene_info = await response.json()
            objects = scene_info["objects"]
            print(f"âœ… Scene '{scene_info['name']}' now contains {len(objects)} objects:")
            for obj in objects:
                print(f"   ğŸ¯ {obj}")
        
        # Step 5: Save the Blender scene
        print(f"\nğŸ’¾ Step 5: Saving Blender Scene")
        scene_path = output_dir / "glittery_bunny.blend"
        
        save_code = f'''
import bpy
import os

# Save the scene
scene_path = r"{scene_path.absolute()}"
bpy.ops.wm.save_as_mainfile(filepath=scene_path)
print(f"âœ… Scene saved to: {{scene_path}}")

# Set up render settings for high quality
scene = bpy.context.scene
scene.render.engine = 'CYCLES'  # Use Cycles for better materials
scene.render.filepath = r"{output_dir.absolute()}/glittery_bunny_render"
scene.render.image_settings.file_format = 'PNG'
scene.render.resolution_x = 1920
scene.render.resolution_y = 1080
scene.render.resolution_percentage = 100

# Enable denoising for cleaner renders
scene.cycles.use_denoising = True
scene.cycles.denoiser = 'OPENIMAGEDENOISE'

print("âœ… Render settings configured for high quality")
print(f"ğŸ“¸ Render will be saved to: {{scene.render.filepath}}")

# Optional: Take a quick screenshot of viewport
'''
        
        async with session.post(f"{blender_url}/execute", json={"code": save_code}) as response:
            save_result = await response.json()
            if save_result["success"]:
                print("âœ… Scene saved successfully!")
                for log in save_result.get("logs", []):
                    if "STDOUT:" in log:
                        stdout = log.replace("STDOUT: ", "").strip()
                        for line in stdout.split('\n'):
                            if line.strip():
                                print(f"   ğŸ’¾ {line}")
            else:
                print(f"âŒ Save failed: {save_result.get('error')}")
        
        # Step 6: Render the scene
        print(f"\nğŸ¬ Step 6: Rendering Glittery Pink Bunny")
        render_code = '''
import bpy

print("ğŸ¬ Starting render...")
# Render the scene
bpy.ops.render.render(write_still=True)
print("âœ… Render completed!")
print(f"ğŸ“¸ Render saved to: {bpy.context.scene.render.filepath}.png")
'''
        
        async with session.post(f"{blender_url}/execute", json={"code": render_code, "timeout": 120}) as response:
            render_result = await response.json()
            if render_result["success"]:
                print("âœ… Rendering completed!")
                for log in render_result.get("logs", []):
                    if "STDOUT:" in log:
                        stdout = log.replace("STDOUT: ", "").strip()
                        for line in stdout.split('\n'):
                            if line.strip():
                                print(f"   ğŸ¬ {line}")
            else:
                print(f"âš ï¸  Render may have issues: {render_result.get('error')}")
        
        # Step 7: Create project summary
        print(f"\nğŸ“‹ Step 7: Creating Project Summary")
        summary = f"""# Glittery Pink Bunny - LL3M E2E Test Results

## Project Details
- **Created**: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
- **Prompt**: "{prompt}"
- **Model Used**: {model_name}
- **Output Directory**: {output_dir.name}

## Generated Files
- `generated_bunny_code.py` - AI-generated Blender Python code
- `glittery_bunny.blend` - Blender scene file
- `glittery_bunny_render.png` - Final rendered image

## Workflow Summary
âœ… LM Studio AI Code Generation  
âœ… Blender Code Execution  
âœ… Scene Creation & Verification  
âœ… Scene File Saving  
âœ… High-Quality Rendering  

## Scene Objects
{chr(10).join(f"- {obj}" for obj in objects)}

## Next Steps
1. Open `glittery_bunny.blend` in Blender to view/edit the scene
2. Check `glittery_bunny_render.png` for the final rendered result
3. Modify the generated code for variations or improvements

---
Generated by LL3M - Local LLM + Blender Integration
"""
        
        summary_path = output_dir / "README.md"
        with open(summary_path, "w") as f:
            f.write(summary)
        
        print("=" * 60)
        print("ğŸ‰ GLITTERY PINK BUNNY E2E TEST COMPLETED!")
        print(f"\nğŸ“ All files saved to: {output_dir.absolute()}")
        print(f"ğŸ­ Scene file: glittery_bunny.blend")
        print(f"ğŸ¬ Render: glittery_bunny_render.png") 
        print(f"ğŸ’» Code: generated_bunny_code.py")
        print(f"ğŸ“‹ Summary: README.md")
        
        print(f"\nğŸš€ LL3M Workflow Results:")
        print(f"  âœ… AI-Generated Blender Code")
        print(f"  âœ… Successfully Executed in Blender")
        print(f"  âœ… Created {len(objects)} Scene Objects")
        print(f"  âœ… Saved High-Quality Scene & Render")
        print(f"  âœ… Complete Local LLM + Blender Pipeline!")
        
        return True


if __name__ == "__main__":
    print("ğŸ°âœ¨ Starting Glittery Pink Bunny E2E Test...")
    success = asyncio.run(create_glittery_bunny_e2e())
    
    if success:
        print(f"\nğŸ¯ RESULT: E2E Glittery Pink Bunny Creation SUCCESSFUL!")
        print("   Your glittery pink bunny has been created and rendered! ğŸ°âœ¨")
    else:
        print(f"\nâŒ RESULT: E2E test failed. Check output above.")
        exit(1)